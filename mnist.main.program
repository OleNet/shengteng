{ // block 0
    var image : fluid.VarType.LOD_TENSOR.shape(-1, 2).astype(VarType.FP32)
    var index : fluid.VarType.LOD_TENSOR.shape(-1,).astype(VarType.INT32)
    var label : fluid.VarType.LOD_TENSOR.shape(-1, 1).astype(VarType.INT64)
    var print_image_0.tmp_0 : fluid.VarType.LOD_TENSOR.shape(-1, 2).astype(VarType.FP32)
    persist trainable param fc_0.w_0 : fluid.VarType.LOD_TENSOR.shape(2, 3).astype(VarType.FP32)
    var fc_0.tmp_0 : fluid.VarType.LOD_TENSOR.shape(-1, 3).astype(VarType.FP32)
    persist trainable param fc_1.w_0 : fluid.VarType.LOD_TENSOR.shape(3, 3).astype(VarType.FP32)
    var fc_1.tmp_0 : fluid.VarType.LOD_TENSOR.shape(-1, 3).astype(VarType.FP32)
    var equal_0.tmp_0 : fluid.VarType.LOD_TENSOR.shape(-1, 3).astype(VarType.BOOL)
    var cast_0.tmp_0 : fluid.VarType.LOD_TENSOR.shape(-1, 3).astype(VarType.FP32)
    var print_cast_0.tmp_0_0.tmp_0 : fluid.VarType.LOD_TENSOR.shape(-1, 3).astype(VarType.FP32)
    var tmp_0 : fluid.VarType.LOD_TENSOR.shape(-1, 3).astype(VarType.FP32)
    var print_fc_0.tmp_0_0.tmp_0 : fluid.VarType.LOD_TENSOR.shape(-1, 3).astype(VarType.FP32)
    var print_fc_1.tmp_0_0.tmp_0 : fluid.VarType.LOD_TENSOR.shape(-1, 3).astype(VarType.FP32)
    var softmax_with_cross_entropy_0.tmp_0 : fluid.VarType.LOD_TENSOR.shape(-1, 3).astype(VarType.FP32)
    var softmax_with_cross_entropy_0.tmp_1 : fluid.VarType.LOD_TENSOR.shape(-1, 1).astype(VarType.FP32)
    var print_softmax_with_cross_entropy_0.tmp_1_0.tmp_0 : fluid.VarType.LOD_TENSOR.shape(-1, 1).astype(VarType.FP32)
    var fill_constant_1.tmp_0 : fluid.VarType.LOD_TENSOR.shape(1,).astype(VarType.FP32)
    var fill_constant_3.tmp_0 : fluid.VarType.LOD_TENSOR.shape(1,).astype(VarType.FP32)
    var fill_constant_5.tmp_0 : fluid.VarType.LOD_TENSOR.shape(1,).astype(VarType.FP32)
    var range_0.tmp_0 : fluid.VarType.LOD_TENSOR.shape(-1,).astype(VarType.FP32)
    var expand_0.tmp_0 : fluid.VarType.LOD_TENSOR.shape(-1, 6).astype(VarType.FP32)
    var unsqueeze2_0.tmp_0 : fluid.VarType.LOD_TENSOR.shape(-1, 3, 1).astype(VarType.FP32)
    var unsqueeze2_0.tmp_1 : fluid.VarType.LOD_TENSOR.shape(0, -1, 3).astype(VarType.FP32)
    var squeeze_0.tmp_0 : fluid.VarType.LOD_TENSOR.shape(-1, 3).astype(VarType.FP32)
    var squeeze_0.tmp_1 : fluid.VarType.LOD_TENSOR.shape(0, -1, 3, 1).astype(VarType.FP32)
    var reduce_sum_0.tmp_0 : fluid.VarType.LOD_TENSOR.shape(1,).astype(VarType.FP32)
    var tmp_1 : fluid.VarType.LOD_TENSOR.shape(1,).astype(VarType.FP32)
    var print_tmp_1_0.tmp_0 : fluid.VarType.LOD_TENSOR.shape(1,).astype(VarType.FP32)
    var cast_0.tmp_0@GRAD : fluid.VarType.LOD_TENSOR.shape(-1, 3).astype(VarType.FP32)
    var fc_0.w_0@GRAD : fluid.VarType.LOD_TENSOR.shape(2, 3).astype(VarType.FP32)
    var print_softmax_with_cross_entropy_0.tmp_1_0.tmp_0@GRAD : fluid.VarType.LOD_TENSOR.shape(-1, 1).astype(VarType.FP32)
    var fc_1.w_0@GRAD : fluid.VarType.LOD_TENSOR.shape(3, 3).astype(VarType.FP32)
    var print_image_0.tmp_0@GRAD : fluid.VarType.LOD_TENSOR.shape(-1, 2).astype(VarType.FP32)
    var fc_0.tmp_0@GRAD : fluid.VarType.LOD_TENSOR.shape(-1, 3).astype(VarType.FP32)
    var print_tmp_1_0.tmp_0@GRAD : fluid.VarType.LOD_TENSOR.shape(1,).astype(VarType.FP32)
    var tmp_1@GRAD : fluid.VarType.LOD_TENSOR.shape(1,).astype(VarType.FP32)
    var reduce_sum_0.tmp_0@GRAD : fluid.VarType.LOD_TENSOR.shape(1,).astype(VarType.FP32)
    var softmax_with_cross_entropy_0.tmp_1@GRAD : fluid.VarType.LOD_TENSOR.shape(-1, 1).astype(VarType.FP32)
    var tmp_0@GRAD : fluid.VarType.LOD_TENSOR.shape(-1, 3).astype(VarType.FP32)
    var fc_1.tmp_0@GRAD : fluid.VarType.LOD_TENSOR.shape(-1, 3).astype(VarType.FP32)
    persist var learning_rate_0 : fluid.VarType.LOD_TENSOR.shape(1,).astype(VarType.FP32)

    {Out=['print_image_0.tmp_0']} = print(inputs={In=['image']}, first_n = -1, is_forward = True, message = image_layer_norm, op_device = , op_namescope = /, op_role = 0, op_role_var = [], print_phase = BOTH, print_tensor_layout = True, print_tensor_lod = True, print_tensor_name = True, print_tensor_shape = True, print_tensor_type = True, summarize = 20)
    {Out=['fc_0.tmp_0']} = mul(inputs={X=['print_image_0.tmp_0'], Y=['fc_0.w_0']}, force_fp32_output = False, op_device = , op_namescope = /, op_role = 0, op_role_var = [], scale_out = 1.0, scale_x = 1.0, scale_y = [1.0], use_mkldnn = False, x_num_col_dims = 1, y_num_col_dims = 1)
    {Out=['fc_1.tmp_0']} = mul(inputs={X=['fc_0.tmp_0'], Y=['fc_1.w_0']}, force_fp32_output = False, op_device = , op_namescope = /, op_role = 0, op_role_var = [], scale_out = 1.0, scale_x = 1.0, scale_y = [1.0], use_mkldnn = False, x_num_col_dims = 1, y_num_col_dims = 1)
    {Out=['equal_0.tmp_0']} = equal(inputs={X=['fc_0.tmp_0'], Y=['fc_0.tmp_0']}, axis = -1, force_cpu = False, op_device = , op_namescope = /, op_role = 0, op_role_var = [])
    {Out=['cast_0.tmp_0']} = cast(inputs={X=['equal_0.tmp_0']}, in_dtype = 0, op_device = , op_namescope = /, op_role = 0, op_role_var = [], out_dtype = 5)
    {Out=['print_cast_0.tmp_0_0.tmp_0']} = print(inputs={In=['cast_0.tmp_0']}, first_n = -1, is_forward = True, message = equal x>>>>>>>>>>>>>>> , op_device = , op_namescope = /, op_role = 0, op_role_var = [], print_phase = BOTH, print_tensor_layout = True, print_tensor_lod = True, print_tensor_name = True, print_tensor_shape = True, print_tensor_type = True, summarize = 20)
    {Out=['tmp_0']} = elementwise_mul(inputs={X=['fc_1.tmp_0'], Y=['cast_0.tmp_0']}, Scale_out = 1.0, Scale_x = 1.0, Scale_y = 1.0, axis = -1, mkldnn_data_type = float32, op_device = , op_namescope = /, op_role = 0, op_role_var = [], use_mkldnn = False, use_quantizer = False, x_data_format = , y_data_format = )
    {Out=['print_fc_0.tmp_0_0.tmp_0']} = print(inputs={In=['fc_0.tmp_0']}, first_n = -1, is_forward = True, message = fc0, op_device = , op_namescope = /, op_role = 0, op_role_var = [], print_phase = BOTH, print_tensor_layout = True, print_tensor_lod = True, print_tensor_name = True, print_tensor_shape = True, print_tensor_type = True, summarize = 20)
    {Out=['print_fc_1.tmp_0_0.tmp_0']} = print(inputs={In=['fc_1.tmp_0']}, first_n = -1, is_forward = True, message = fc1, op_device = , op_namescope = /, op_role = 0, op_role_var = [], print_phase = BOTH, print_tensor_layout = True, print_tensor_lod = True, print_tensor_name = True, print_tensor_shape = True, print_tensor_type = True, summarize = 20)
    {Loss=['softmax_with_cross_entropy_0.tmp_1'], Softmax=['softmax_with_cross_entropy_0.tmp_0']} = softmax_with_cross_entropy(inputs={Label=['label'], Logits=['tmp_0']}, axis = -1, ignore_index = -100, numeric_stable_mode = True, op_device = , op_namescope = /, op_role = 0, op_role_var = [], soft_label = False)
    {Out=['print_softmax_with_cross_entropy_0.tmp_1_0.tmp_0']} = print(inputs={In=['softmax_with_cross_entropy_0.tmp_1']}, first_n = -1, is_forward = True, message = cross_entropy, op_device = , op_namescope = /, op_role = 0, op_role_var = [], print_phase = BOTH, print_tensor_layout = True, print_tensor_lod = True, print_tensor_name = True, print_tensor_shape = True, print_tensor_type = True, summarize = 20)
    {Out=['fill_constant_1.tmp_0']} = fill_constant(inputs={ShapeTensor=[], ShapeTensorList=[], ValueTensor=[]}, dtype = 5, force_cpu = False, op_device = cpu, op_namescope = /, op_role = 0, op_role_var = [], shape = [1], str_value = 0.0, value = 0.0)
    {Out=['fill_constant_3.tmp_0']} = fill_constant(inputs={ShapeTensor=[], ShapeTensorList=[], ValueTensor=[]}, dtype = 5, force_cpu = False, op_device = cpu, op_namescope = /, op_role = 0, op_role_var = [], shape = [1], str_value = 3.0, value = 0.0)
    {Out=['fill_constant_5.tmp_0']} = fill_constant(inputs={ShapeTensor=[], ShapeTensorList=[], ValueTensor=[]}, dtype = 5, force_cpu = False, op_device = cpu, op_namescope = /, op_role = 0, op_role_var = [], shape = [1], str_value = 1.0, value = 0.0)
    {Out=['range_0.tmp_0']} = range(inputs={End=['fill_constant_3.tmp_0'], Start=['fill_constant_1.tmp_0'], Step=['fill_constant_5.tmp_0']}, op_device = , op_namescope = /, op_role = 0, op_role_var = [])
    {Out=['expand_0.tmp_0']} = expand(inputs={ExpandTimes=[], X=['print_fc_0.tmp_0_0.tmp_0'], expand_times_tensor=[]}, expand_times = [1, 2], op_device = , op_namescope = /, op_role = 0, op_role_var = [])
    {Out=['unsqueeze2_0.tmp_0'], XShape=['unsqueeze2_0.tmp_1']} = unsqueeze2(inputs={AxesTensor=[], AxesTensorList=[], X=['print_fc_0.tmp_0_0.tmp_0']}, axes = [2], op_device = , op_namescope = /, op_role = 0, op_role_var = [])
    {Out=['squeeze_0.tmp_0'], XShape=['squeeze_0.tmp_1']} = squeeze2(inputs={X=['unsqueeze2_0.tmp_0']}, axes = [2], op_device = , op_namescope = /, op_role = 0, op_role_var = [])
    {Out=['reduce_sum_0.tmp_0']} = reduce_sum(inputs={X=['print_softmax_with_cross_entropy_0.tmp_1_0.tmp_0']}, dim = [0], in_dtype = -1, keep_dim = False, op_device = , op_namescope = /, op_role = 0, op_role_var = [], out_dtype = -1, reduce_all = True)
    {Out=['tmp_1']} = scale(inputs={ScaleTensor=[], X=['reduce_sum_0.tmp_0']}, bias = 10.0, bias_after_scale = True, op_device = , op_namescope = /, op_role = 0, op_role_var = [], scale = 1.0)
    {Out=['print_tmp_1_0.tmp_0']} = print(inputs={In=['tmp_1']}, first_n = -1, is_forward = True, message = cost, op_device = , op_namescope = /, op_role = 256, op_role_var = [], print_phase = BOTH, print_tensor_layout = True, print_tensor_lod = True, print_tensor_name = True, print_tensor_shape = True, print_tensor_type = True, summarize = 20)
    {Out=['print_tmp_1_0.tmp_0@GRAD']} = fill_constant(inputs={}, dtype = 5, force_cpu = False, op_device = , op_role = 257, shape = [1], value = 1.0)
    {Out=['tmp_1@GRAD']} = print(inputs={In=['print_tmp_1_0.tmp_0@GRAD']}, first_n = -1, is_forward = False, message = cost, op_device = , op_namescope = /, op_role = 1, op_role_var = [], print_phase = BOTH, print_tensor_layout = True, print_tensor_lod = True, print_tensor_name = True, print_tensor_shape = True, print_tensor_type = True, summarize = 20)
    {Out=['reduce_sum_0.tmp_0@GRAD']} = scale(inputs={ScaleTensor=[], X=['tmp_1@GRAD']}, bias = 0.0, bias_after_scale = True, op_device = , op_role = 1, scale = 1.0)
    {X@GRAD=['print_softmax_with_cross_entropy_0.tmp_1_0.tmp_0@GRAD']} = reduce_sum_grad(inputs={Out@GRAD=['reduce_sum_0.tmp_0@GRAD'], X=['print_softmax_with_cross_entropy_0.tmp_1_0.tmp_0']}, dim = [0], in_dtype = -1, keep_dim = False, op_device = , op_namescope = /, op_role = 1, op_role_var = [], out_dtype = -1, reduce_all = True)
    {Out=['softmax_with_cross_entropy_0.tmp_1@GRAD']} = print(inputs={In=['print_softmax_with_cross_entropy_0.tmp_1_0.tmp_0@GRAD']}, first_n = -1, is_forward = False, message = cross_entropy, op_device = , op_namescope = /, op_role = 1, op_role_var = [], print_phase = BOTH, print_tensor_layout = True, print_tensor_lod = True, print_tensor_name = True, print_tensor_shape = True, print_tensor_type = True, summarize = 20)
    {Logits@GRAD=['tmp_0@GRAD']} = softmax_with_cross_entropy_grad(inputs={Label=['label'], Loss@GRAD=['softmax_with_cross_entropy_0.tmp_1@GRAD'], Softmax=['softmax_with_cross_entropy_0.tmp_0']}, axis = -1, ignore_index = -100, numeric_stable_mode = True, op_device = , op_namescope = /, op_role = 1, op_role_var = [], soft_label = False)
    {X@GRAD=['fc_1.tmp_0@GRAD'], Y@GRAD=['cast_0.tmp_0@GRAD']} = elementwise_mul_grad(inputs={Out@GRAD=['tmp_0@GRAD'], X=['fc_1.tmp_0'], Y=['cast_0.tmp_0']}, Scale_out = 1.0, Scale_x = 1.0, Scale_y = 1.0, axis = -1, mkldnn_data_type = float32, op_device = , op_namescope = /, op_role = 1, op_role_var = [], use_mkldnn = False, use_quantizer = False, x_data_format = , y_data_format = )
    {X@GRAD=['fc_0.tmp_0@GRAD'], Y@GRAD=['fc_1.w_0@GRAD']} = mul_grad(inputs={Out@GRAD=['fc_1.tmp_0@GRAD'], X=['fc_0.tmp_0'], Y=['fc_1.w_0']}, force_fp32_output = False, op_device = , op_namescope = /, op_role = 1, op_role_var = ['fc_1.w_0', 'fc_1.w_0@GRAD'], scale_out = 1.0, scale_x = 1.0, scale_y = [1.0], use_mkldnn = False, x_num_col_dims = 1, y_num_col_dims = 1)
    {X@GRAD=['print_image_0.tmp_0@GRAD'], Y@GRAD=['fc_0.w_0@GRAD']} = mul_grad(inputs={Out@GRAD=['fc_0.tmp_0@GRAD'], X=['print_image_0.tmp_0'], Y=['fc_0.w_0']}, force_fp32_output = False, op_device = , op_namescope = /, op_role = 1, op_role_var = ['fc_0.w_0', 'fc_0.w_0@GRAD'], scale_out = 1.0, scale_x = 1.0, scale_y = [1.0], use_mkldnn = False, x_num_col_dims = 1, y_num_col_dims = 1)
    {ParamOut=['fc_0.w_0']} = sgd(inputs={Grad=['fc_0.w_0@GRAD'], LearningRate=['learning_rate_0'], Param=['fc_0.w_0']}, op_device = , op_namescope = /optimizer/, op_role = 2, op_role_var = ['fc_0.w_0', 'fc_0.w_0@GRAD'])
    {ParamOut=['fc_1.w_0']} = sgd(inputs={Grad=['fc_1.w_0@GRAD'], LearningRate=['learning_rate_0'], Param=['fc_1.w_0']}, op_device = , op_namescope = /optimizer_1/, op_role = 2, op_role_var = ['fc_1.w_0', 'fc_1.w_0@GRAD'])
}

